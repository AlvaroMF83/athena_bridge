<meta http-equiv="Content-Type" content="text/html; charset=utf-8"><link type="text/css" rel="stylesheet" href="resources/sheet.css" >
<style type="text/css">.ritz .waffle a { color: inherit; }.ritz .waffle .s4{border-bottom:1px SOLID #d9d9d9;border-right:1px SOLID #d9d9d9;background-color:#c9daf8;text-align:left;font-weight:bold;color:#000000;font-family:docs-Lato,Arial;font-size:14pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s0{background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:docs-Lato,Arial;font-size:24pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s3{border-bottom:1px SOLID #d9d9d9;border-right:1px SOLID #d9d9d9;background-color:#6d9eeb;text-align:center;font-weight:bold;color:#ffffff;font-family:docs-Lato,Arial;font-size:9pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s1{border-bottom:1px SOLID #d9d9d9;background-color:#ffffff;text-align:left;color:#000000;font-family:docs-Lato,Arial;font-size:9pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s2{border-bottom:1px SOLID #d9d9d9;border-right:1px SOLID #d9d9d9;background-color:#6d9eeb;text-align:left;font-weight:bold;color:#ffffff;font-family:docs-Lato,Arial;font-size:9pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s5{border-bottom:1px SOLID #d9d9d9;border-right:1px SOLID #d9d9d9;background-color:#ffffff;text-align:left;color:#000000;font-family:docs-Lato,Arial;font-size:8pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s6{border-bottom:1px SOLID #d9d9d9;border-right:1px SOLID #d9d9d9;background-color:#ffffff;text-align:center;color:#000000;font-family:docs-Lato,Arial;font-size:8pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}</style><div class="ritz grid-container" dir="ltr"><table class="waffle no-grid" cellspacing="0" cellpadding="0"><thead><tr><th class="row-header freezebar-origin-ltr"></th><th id="1474227261C0" style="width:278px;" class="column-headers-background">A</th><th id="1474227261C1" style="width:834px;" class="column-headers-background">B</th><th id="1474227261C2" style="width:143px;" class="column-headers-background">C</th></tr></thead><tbody><tr style="height: 20px"><th id="1474227261R0" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">1</div></th><td class="s0" dir="ltr" colspan="3">Functions</td></tr><tr style="height: 20px"><th id="1474227261R1" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">2</div></th><td class="s1" dir="ltr" colspan="3">A collections of builtin functions available for DataFrame operations. From Apache Spark 3.5.0, all functions support Spark Connect.</td></tr><tr style="height: 20px"><th id="1474227261R2" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">3</div></th><td class="s2" dir="ltr">Nombre</td><td class="s2" dir="ltr">Descripcion</td><td class="s3" dir="ltr">Disponible</td></tr><tr style="height: 20px"><th id="1474227261R3" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">4</div></th><td class="s4" dir="ltr" colspan="3">Normal Functions</td></tr><tr style="height: 20px"><th id="1474227261R4" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">5</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.col.html#pyspark.sql.functions.col">col</a></span>(col)</td><td class="s5" dir="ltr">Returns a <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> based on the given column name.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R5" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">6</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.column.html#pyspark.sql.functions.column">column</a></span>(col)</td><td class="s5" dir="ltr">Returns a <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> based on the given column name.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R6" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">7</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lit.html#pyspark.sql.functions.lit">lit</a></span>(col)</td><td class="s5" dir="ltr">Creates a <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> of literal value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R7" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">8</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.broadcast.html#pyspark.sql.functions.broadcast">broadcast</a></span>(df)</td><td class="s5" dir="ltr">Marks a DataFrame as small enough for use in broadcast joins.</td><td class="s6" dir="ltr">Si, por compatibilidad</td></tr><tr style="height: 20px"><th id="1474227261R8" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">9</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.coalesce.html#pyspark.sql.functions.coalesce">coalesce</a></span>(*cols)</td><td class="s5" dir="ltr">Returns the first column that is not null.</td><td class="s6" dir="ltr">si</td></tr><tr style="height: 20px"><th id="1474227261R9" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">10</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.input_file_name.html#pyspark.sql.functions.input_file_name">input_file_name</a></span>()</td><td class="s5" dir="ltr">Creates a string column for the file name of the current Spark task.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R10" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">11</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.isnan.html#pyspark.sql.functions.isnan">isnan</a></span>(col)</td><td class="s5" dir="ltr">An expression that returns true if the column is NaN.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R11" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">12</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.isnull.html#pyspark.sql.functions.isnull">isnull</a></span>(col)</td><td class="s5" dir="ltr">An expression that returns true if the column is null.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R12" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">13</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.monotonically_increasing_id.html#pyspark.sql.functions.monotonically_increasing_id">monotonically_increasing_id</a></span>()</td><td class="s5" dir="ltr">A column that generates monotonically increasing 64-bit integers.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R13" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">14</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.named_struct.html#pyspark.sql.functions.named_struct">named_struct</a></span>(*cols)</td><td class="s5" dir="ltr">Creates a struct with the given field names and values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R14" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">15</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.nanvl.html#pyspark.sql.functions.nanvl">nanvl</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns col1 if it is not NaN, or col2 if col1 is NaN.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R15" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">16</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rand.html#pyspark.sql.functions.rand">rand</a></span>([seed])</td><td class="s5" dir="ltr">Generates a random column with independent and identically distributed (i.i.d.) samples uniformly distributed in [0.0, 1.0).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R16" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">17</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.randn.html#pyspark.sql.functions.randn">randn</a></span>([seed])</td><td class="s5" dir="ltr">Generates a column with independent and identically distributed (i.i.d.) samples from the standard normal distribution.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R17" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">18</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.spark_partition_id.html#pyspark.sql.functions.spark_partition_id">spark_partition_id</a></span>()</td><td class="s5" dir="ltr">A column for partition ID.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R18" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">19</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.when.html#pyspark.sql.functions.when">when</a></span>(condition, value)</td><td class="s5" dir="ltr">Evaluates a list of conditions and returns one of multiple possible result expressions.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R19" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">20</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitwise_not.html#pyspark.sql.functions.bitwise_not">bitwise_not</a></span>(col)</td><td class="s5" dir="ltr">Computes bitwise not.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R20" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">21</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitwiseNOT.html#pyspark.sql.functions.bitwiseNOT">bitwiseNOT</a></span>(col)</td><td class="s5" dir="ltr">Computes bitwise not.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R21" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">22</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.expr.html#pyspark.sql.functions.expr">expr</a></span>(str)</td><td class="s5" dir="ltr">Parses the expression string into the column that it represents</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R22" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">23</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.greatest.html#pyspark.sql.functions.greatest">greatest</a></span>(*cols)</td><td class="s5" dir="ltr">Returns the greatest value of the list of column names, skipping null values.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R23" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">24</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.least.html#pyspark.sql.functions.least">least</a></span>(*cols)</td><td class="s5" dir="ltr">Returns the least value of the list of column names, skipping null values.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R24" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">25</div></th><td class="s4" dir="ltr" colspan="3">Math Functions</td></tr><tr style="height: 20px"><th id="1474227261R25" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">26</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sqrt.html#pyspark.sql.functions.sqrt">sqrt</a></span>(col)</td><td class="s5" dir="ltr">Computes the square root of the specified float value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R26" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">27</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.abs.html#pyspark.sql.functions.abs">abs</a></span>(col)</td><td class="s5" dir="ltr">Computes the absolute value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R27" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">28</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.acos.html#pyspark.sql.functions.acos">acos</a></span>(col)</td><td class="s5" dir="ltr">Computes inverse cosine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R28" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">29</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.acosh.html#pyspark.sql.functions.acosh">acosh</a></span>(col)</td><td class="s5" dir="ltr">Computes inverse hyperbolic cosine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R29" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">30</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.asin.html#pyspark.sql.functions.asin">asin</a></span>(col)</td><td class="s5" dir="ltr">Computes inverse sine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R30" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">31</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.asinh.html#pyspark.sql.functions.asinh">asinh</a></span>(col)</td><td class="s5" dir="ltr">Computes inverse hyperbolic sine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R31" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">32</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.atan.html#pyspark.sql.functions.atan">atan</a></span>(col)</td><td class="s5" dir="ltr">Compute inverse tangent of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R32" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">33</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.atanh.html#pyspark.sql.functions.atanh">atanh</a></span>(col)</td><td class="s5" dir="ltr">Computes inverse hyperbolic tangent of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R33" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">34</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.atan2.html#pyspark.sql.functions.atan2">atan2</a></span>(col1, col2)</td><td class="s5" dir="ltr">New in version 1.4.0.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R34" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">35</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bin.html#pyspark.sql.functions.bin">bin</a></span>(col)</td><td class="s5" dir="ltr">Returns the string representation of the binary value of the given column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R35" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">36</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cbrt.html#pyspark.sql.functions.cbrt">cbrt</a></span>(col)</td><td class="s5" dir="ltr">Computes the cube-root of the given value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R36" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">37</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ceil.html#pyspark.sql.functions.ceil">ceil</a></span>(col)</td><td class="s5" dir="ltr">Computes the ceiling of the given value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R37" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">38</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ceiling.html#pyspark.sql.functions.ceiling">ceiling</a></span>(col)</td><td class="s5" dir="ltr">Computes the ceiling of the given value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R38" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">39</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.conv.html#pyspark.sql.functions.conv">conv</a></span>(col, fromBase, toBase)</td><td class="s5" dir="ltr">Convert a number in a string column from one base to another.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R39" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">40</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cos.html#pyspark.sql.functions.cos">cos</a></span>(col)</td><td class="s5" dir="ltr">Computes cosine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R40" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">41</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cosh.html#pyspark.sql.functions.cosh">cosh</a></span>(col)</td><td class="s5" dir="ltr">Computes hyperbolic cosine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R41" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">42</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cot.html#pyspark.sql.functions.cot">cot</a></span>(col)</td><td class="s5" dir="ltr">Computes cotangent of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R42" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">43</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.csc.html#pyspark.sql.functions.csc">csc</a></span>(col)</td><td class="s5" dir="ltr">Computes cosecant of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R43" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">44</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.e.html#pyspark.sql.functions.e">e</a></span>()</td><td class="s5" dir="ltr">Returns Euler’s number.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R44" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">45</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.exp.html#pyspark.sql.functions.exp">exp</a></span>(col)</td><td class="s5" dir="ltr">Computes the exponential of the given value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R45" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">46</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.expm1.html#pyspark.sql.functions.expm1">expm1</a></span>(col)</td><td class="s5" dir="ltr">Computes the exponential of the given value minus one.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R46" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">47</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.factorial.html#pyspark.sql.functions.factorial">factorial</a></span>(col)</td><td class="s5" dir="ltr">Computes the factorial of the given value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R47" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">48</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.floor.html#pyspark.sql.functions.floor">floor</a></span>(col)</td><td class="s5" dir="ltr">Computes the floor of the given value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R48" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">49</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hex.html#pyspark.sql.functions.hex">hex</a></span>(col)</td><td class="s5" dir="ltr">Computes hex value of the given column, which could be <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.StringType.html#pyspark.sql.types.StringType">pyspark.sql.types.StringType</a></span>, <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.BinaryType.html#pyspark.sql.types.BinaryType">pyspark.sql.types.BinaryType</a></span>, <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.IntegerType.html#pyspark.sql.types.IntegerType">pyspark.sql.types.IntegerType</a></span> or <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.LongType.html#pyspark.sql.types.LongType">pyspark.sql.types.LongType</a></span>.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R49" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">50</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unhex.html#pyspark.sql.functions.unhex">unhex</a></span>(col)</td><td class="s5" dir="ltr">Inverse of hex.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R50" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">51</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hypot.html#pyspark.sql.functions.hypot">hypot</a></span>(col1, col2)</td><td class="s5" dir="ltr">Computes sqrt(a^2 + b^2) without intermediate overflow or underflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R51" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">52</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ln.html#pyspark.sql.functions.ln">ln</a></span>(col)</td><td class="s5" dir="ltr">Returns the natural logarithm of the argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R52" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">53</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.log.html#pyspark.sql.functions.log">log</a></span>(arg1[, arg2])</td><td class="s5" dir="ltr">Returns the first argument-based logarithm of the second argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R53" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">54</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.log10.html#pyspark.sql.functions.log10">log10</a></span>(col)</td><td class="s5" dir="ltr">Computes the logarithm of the given value in Base 10.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R54" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">55</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.log1p.html#pyspark.sql.functions.log1p">log1p</a></span>(col)</td><td class="s5" dir="ltr">Computes the natural logarithm of the “given value plus one”.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R55" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">56</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.log2.html#pyspark.sql.functions.log2">log2</a></span>(col)</td><td class="s5" dir="ltr">Returns the base-2 logarithm of the argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R56" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">57</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.negate.html#pyspark.sql.functions.negate">negate</a></span>(col)</td><td class="s5" dir="ltr">Returns the negative value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R57" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">58</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.negative.html#pyspark.sql.functions.negative">negative</a></span>(col)</td><td class="s5" dir="ltr">Returns the negative value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R58" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">59</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pi.html#pyspark.sql.functions.pi">pi</a></span>()</td><td class="s5" dir="ltr">Returns Pi.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R59" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">60</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pmod.html#pyspark.sql.functions.pmod">pmod</a></span>(dividend, divisor)</td><td class="s5" dir="ltr">Returns the positive value of dividend mod divisor.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R60" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">61</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.positive.html#pyspark.sql.functions.positive">positive</a></span>(col)</td><td class="s5" dir="ltr">Returns the value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R61" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">62</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pow.html#pyspark.sql.functions.pow">pow</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns the value of the first argument raised to the power of the second argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R62" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">63</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.power.html#pyspark.sql.functions.power">power</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns the value of the first argument raised to the power of the second argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R63" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">64</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rint.html#pyspark.sql.functions.rint">rint</a></span>(col)</td><td class="s5" dir="ltr">Returns the double value that is closest in value to the argument and is equal to a mathematical integer.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R64" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">65</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.round.html#pyspark.sql.functions.round">round</a></span>(col[, scale])</td><td class="s5" dir="ltr">Round the given value to scale decimal places using HALF_UP rounding mode if scale &gt;= 0 or at integral part when scale &lt; 0.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R65" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">66</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bround.html#pyspark.sql.functions.bround">bround</a></span>(col[, scale])</td><td class="s5" dir="ltr">Round the given value to scale decimal places using HALF_EVEN rounding mode if scale &gt;= 0 or at integral part when scale &lt; 0.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R66" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">67</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sec.html#pyspark.sql.functions.sec">sec</a></span>(col)</td><td class="s5" dir="ltr">Computes secant of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R67" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">68</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.shiftleft.html#pyspark.sql.functions.shiftleft">shiftleft</a></span>(col, numBits)</td><td class="s5" dir="ltr">Shift the given value numBits left.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R68" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">69</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.shiftright.html#pyspark.sql.functions.shiftright">shiftright</a></span>(col, numBits)</td><td class="s5" dir="ltr">(Signed) shift the given value numBits right.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R69" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">70</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.shiftrightunsigned.html#pyspark.sql.functions.shiftrightunsigned">shiftrightunsigned</a></span>(col, numBits)</td><td class="s5" dir="ltr">Unsigned shift the given value numBits right.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R70" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">71</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sign.html#pyspark.sql.functions.sign">sign</a></span>(col)</td><td class="s5" dir="ltr">Computes the signum of the given value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R71" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">72</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.signum.html#pyspark.sql.functions.signum">signum</a></span>(col)</td><td class="s5" dir="ltr">Computes the signum of the given value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R72" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">73</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sin.html#pyspark.sql.functions.sin">sin</a></span>(col)</td><td class="s5" dir="ltr">Computes sine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R73" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">74</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sinh.html#pyspark.sql.functions.sinh">sinh</a></span>(col)</td><td class="s5" dir="ltr">Computes hyperbolic sine of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R74" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">75</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.tan.html#pyspark.sql.functions.tan">tan</a></span>(col)</td><td class="s5" dir="ltr">Computes tangent of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R75" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">76</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.tanh.html#pyspark.sql.functions.tanh">tanh</a></span>(col)</td><td class="s5" dir="ltr">Computes hyperbolic tangent of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R76" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">77</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.toDegrees.html#pyspark.sql.functions.toDegrees">toDegrees</a></span>(col)</td><td class="s5" dir="ltr">New in version 1.4.0.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R77" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">78</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_add.html#pyspark.sql.functions.try_add">try_add</a></span>(left, right)</td><td class="s5" dir="ltr">Returns the sum of left`and `right and the result is null on overflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R78" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">79</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_avg.html#pyspark.sql.functions.try_avg">try_avg</a></span>(col)</td><td class="s5" dir="ltr">Returns the mean calculated from values of a group and the result is null on overflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R79" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">80</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_divide.html#pyspark.sql.functions.try_divide">try_divide</a></span>(left, right)</td><td class="s5" dir="ltr">Returns dividend/divisor.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R80" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">81</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_multiply.html#pyspark.sql.functions.try_multiply">try_multiply</a></span>(left, right)</td><td class="s5" dir="ltr">Returns left`*`right and the result is null on overflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R81" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">82</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_subtract.html#pyspark.sql.functions.try_subtract">try_subtract</a></span>(left, right)</td><td class="s5" dir="ltr">Returns left-right and the result is null on overflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R82" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">83</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_sum.html#pyspark.sql.functions.try_sum">try_sum</a></span>(col)</td><td class="s5" dir="ltr">Returns the sum calculated from values of a group and the result is null on overflow.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R83" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">84</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_to_binary.html#pyspark.sql.functions.try_to_binary">try_to_binary</a></span>(col[, format])</td><td class="s5" dir="ltr">This is a special version of to_binary that performs the same operation, but returns a NULL value instead of raising an error if the conversion cannot be performed.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R84" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">85</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_to_number.html#pyspark.sql.functions.try_to_number">try_to_number</a></span>(col, format)</td><td class="s5" dir="ltr">Convert string ‘col’ to a number based on the string format format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R85" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">86</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.degrees.html#pyspark.sql.functions.degrees">degrees</a></span>(col)</td><td class="s5" dir="ltr">Converts an angle measured in radians to an approximately equivalent angle measured in degrees.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R86" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">87</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.toRadians.html#pyspark.sql.functions.toRadians">toRadians</a></span>(col)</td><td class="s5" dir="ltr">New in version 1.4.0.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R87" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">88</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.radians.html#pyspark.sql.functions.radians">radians</a></span>(col)</td><td class="s5" dir="ltr">Converts an angle measured in degrees to an approximately equivalent angle measured in radians.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R88" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">89</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.width_bucket.html#pyspark.sql.functions.width_bucket">width_bucket</a></span>(v, min, max, numBucket)</td><td class="s5" dir="ltr">Returns the bucket number into which the value of this expression would fall after being evaluated.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R89" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">90</div></th><td class="s4" dir="ltr" colspan="3">Datetime Functions</td></tr><tr style="height: 20px"><th id="1474227261R90" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">91</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.add_months.html#pyspark.sql.functions.add_months">add_months</a></span>(start, months)</td><td class="s5" dir="ltr">Returns the date that is months months after start.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R91" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">92</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.convert_timezone.html#pyspark.sql.functions.convert_timezone">convert_timezone</a></span>(sourceTz, targetTz, sourceTs)</td><td class="s5" dir="ltr">Converts the timestamp without time zone sourceTs from the sourceTz time zone to targetTz.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R92" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">93</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.curdate.html#pyspark.sql.functions.curdate">curdate</a></span>()</td><td class="s5" dir="ltr">Returns the current date at the start of query evaluation as a DateType column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R93" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">94</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_date.html#pyspark.sql.functions.current_date">current_date</a></span>()</td><td class="s5" dir="ltr">Returns the current date at the start of query evaluation as a DateType column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R94" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">95</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_timestamp.html#pyspark.sql.functions.current_timestamp">current_timestamp</a></span>()</td><td class="s5" dir="ltr">Returns the current timestamp at the start of query evaluation as a TimestampType column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R95" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">96</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_timezone.html#pyspark.sql.functions.current_timezone">current_timezone</a></span>()</td><td class="s5" dir="ltr">Returns the current session local timezone.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R96" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">97</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_add.html#pyspark.sql.functions.date_add">date_add</a></span>(start, days)</td><td class="s5" dir="ltr">Returns the date that is days days after start.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R97" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">98</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_diff.html#pyspark.sql.functions.date_diff">date_diff</a></span>(end, start)</td><td class="s5" dir="ltr">Returns the number of days from start to end.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R98" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">99</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_format.html#pyspark.sql.functions.date_format">date_format</a></span>(date, format)</td><td class="s5" dir="ltr">Converts a date/timestamp/string to a value of string in the format specified by the date format given by the second argument.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R99" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">100</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_from_unix_date.html#pyspark.sql.functions.date_from_unix_date">date_from_unix_date</a></span>(days)</td><td class="s5" dir="ltr">Create date from the number of days since 1970-01-01.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R100" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">101</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_sub.html#pyspark.sql.functions.date_sub">date_sub</a></span>(start, days)</td><td class="s5" dir="ltr">Returns the date that is days days before start.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R101" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">102</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_trunc.html#pyspark.sql.functions.date_trunc">date_trunc</a></span>(format, timestamp)</td><td class="s5" dir="ltr">Returns timestamp truncated to the unit specified by the format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R102" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">103</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dateadd.html#pyspark.sql.functions.dateadd">dateadd</a></span>(start, days)</td><td class="s5" dir="ltr">Returns the date that is days days after start.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R103" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">104</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.datediff.html#pyspark.sql.functions.datediff">datediff</a></span>(end, start)</td><td class="s5" dir="ltr">Returns the number of days from start to end.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R104" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">105</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.day.html#pyspark.sql.functions.day">day</a></span>(col)</td><td class="s5" dir="ltr">Extract the day of the month of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R105" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">106</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_part.html#pyspark.sql.functions.date_part">date_part</a></span>(field, source)</td><td class="s5" dir="ltr">Extracts a part of the date/timestamp or interval source.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R106" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">107</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.datepart.html#pyspark.sql.functions.datepart">datepart</a></span>(field, source)</td><td class="s5" dir="ltr">Extracts a part of the date/timestamp or interval source.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R107" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">108</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dayofmonth.html#pyspark.sql.functions.dayofmonth">dayofmonth</a></span>(col)</td><td class="s5" dir="ltr">Extract the day of the month of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R108" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">109</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dayofweek.html#pyspark.sql.functions.dayofweek">dayofweek</a></span>(col)</td><td class="s5" dir="ltr">Extract the day of the week of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R109" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">110</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dayofyear.html#pyspark.sql.functions.dayofyear">dayofyear</a></span>(col)</td><td class="s5" dir="ltr">Extract the day of the year of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R110" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">111</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.extract.html#pyspark.sql.functions.extract">extract</a></span>(field, source)</td><td class="s5" dir="ltr">Extracts a part of the date/timestamp or interval source.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R111" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">112</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.second.html#pyspark.sql.functions.second">second</a></span>(col)</td><td class="s5" dir="ltr">Extract the seconds of a given date as integer.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R112" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">113</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.weekofyear.html#pyspark.sql.functions.weekofyear">weekofyear</a></span>(col)</td><td class="s5" dir="ltr">Extract the week number of a given date as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R113" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">114</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.year.html#pyspark.sql.functions.year">year</a></span>(col)</td><td class="s5" dir="ltr">Extract the year of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R114" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">115</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.quarter.html#pyspark.sql.functions.quarter">quarter</a></span>(col)</td><td class="s5" dir="ltr">Extract the quarter of a given date/timestamp as integer.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R115" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">116</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.month.html#pyspark.sql.functions.month">month</a></span>(col)</td><td class="s5" dir="ltr">Extract the month of a given date/timestamp as integer.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R116" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">117</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.last_day.html#pyspark.sql.functions.last_day">last_day</a></span>(date)</td><td class="s5" dir="ltr">Returns the last day of the month which the given date belongs to.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R117" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">118</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.localtimestamp.html#pyspark.sql.functions.localtimestamp">localtimestamp</a></span>()</td><td class="s5" dir="ltr">Returns the current timestamp without time zone at the start of query evaluation as a timestamp without time zone column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R118" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">119</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_dt_interval.html#pyspark.sql.functions.make_dt_interval">make_dt_interval</a></span>([days, hours, mins, secs])</td><td class="s5" dir="ltr">Make DayTimeIntervalType duration from days, hours, mins and secs.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R119" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">120</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_interval.html#pyspark.sql.functions.make_interval">make_interval</a></span>([years, months, weeks, days, …])</td><td class="s5" dir="ltr">Make interval from years, months, weeks, days, hours, mins and secs.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R120" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">121</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_timestamp.html#pyspark.sql.functions.make_timestamp">make_timestamp</a></span>(years, months, days, hours, …)</td><td class="s5" dir="ltr">Create timestamp from years, months, days, hours, mins, secs and timezone fields.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R121" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">122</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_timestamp_ltz.html#pyspark.sql.functions.make_timestamp_ltz">make_timestamp_ltz</a></span>(years, months, days, …)</td><td class="s5" dir="ltr">Create the current timestamp with local time zone from years, months, days, hours, mins, secs and timezone fields.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R122" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">123</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_timestamp_ntz.html#pyspark.sql.functions.make_timestamp_ntz">make_timestamp_ntz</a></span>(years, months, days, …)</td><td class="s5" dir="ltr">Create local date-time from years, months, days, hours, mins, secs fields.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R123" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">124</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_ym_interval.html#pyspark.sql.functions.make_ym_interval">make_ym_interval</a></span>([years, months])</td><td class="s5" dir="ltr">Make year-month interval from years, months.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R124" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">125</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.minute.html#pyspark.sql.functions.minute">minute</a></span>(col)</td><td class="s5" dir="ltr">Extract the minutes of a given timestamp as integer.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R125" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">126</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.months_between.html#pyspark.sql.functions.months_between">months_between</a></span>(date1, date2[, roundOff])</td><td class="s5" dir="ltr">Returns number of months between dates date1 and date2.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R126" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">127</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.next_day.html#pyspark.sql.functions.next_day">next_day</a></span>(date, dayOfWeek)</td><td class="s5" dir="ltr">Returns the first date which is later than the value of the date column based on second week day argument.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R127" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">128</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hour.html#pyspark.sql.functions.hour">hour</a></span>(col)</td><td class="s5" dir="ltr">Extract the hours of a given timestamp as integer.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R128" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">129</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.make_date.html#pyspark.sql.functions.make_date">make_date</a></span>(year, month, day)</td><td class="s5" dir="ltr">Returns a column with a date built from the year, month and day columns.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R129" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">130</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.now.html#pyspark.sql.functions.now">now</a></span>()</td><td class="s5" dir="ltr">Returns the current timestamp at the start of query evaluation.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R130" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">131</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_unixtime.html#pyspark.sql.functions.from_unixtime">from_unixtime</a></span>(timestamp[, format])</td><td class="s5" dir="ltr">Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the given format.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R131" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">132</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_timestamp.html#pyspark.sql.functions.unix_timestamp">unix_timestamp</a></span>([timestamp, format])</td><td class="s5" dir="ltr">Convert time string with given pattern (‘yyyy-MM-dd HH:mm:ss’, by default) to Unix time stamp (in seconds), using the default timezone and the default locale, returns null if failed.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R132" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">133</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_unix_timestamp.html#pyspark.sql.functions.to_unix_timestamp">to_unix_timestamp</a></span>(timestamp[, format])</td><td class="s5" dir="ltr">Returns the UNIX timestamp of the given time.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R133" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">134</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_timestamp.html#pyspark.sql.functions.to_timestamp">to_timestamp</a></span>(col[, format])</td><td class="s5" dir="ltr">Converts a <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> into <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.TimestampType.html#pyspark.sql.types.TimestampType">pyspark.sql.types.TimestampType</a></span> using the optionally specified format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R134" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">135</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_timestamp_ltz.html#pyspark.sql.functions.to_timestamp_ltz">to_timestamp_ltz</a></span>(timestamp[, format])</td><td class="s5" dir="ltr">Parses the timestamp with the format to a timestamp without time zone.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R135" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">136</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_timestamp_ntz.html#pyspark.sql.functions.to_timestamp_ntz">to_timestamp_ntz</a></span>(timestamp[, format])</td><td class="s5" dir="ltr">Parses the timestamp with the format to a timestamp without time zone.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R136" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">137</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_date.html#pyspark.sql.functions.to_date">to_date</a></span>(col[, format])</td><td class="s5" dir="ltr">Converts a <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> into <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.types.DateType.html#pyspark.sql.types.DateType">pyspark.sql.types.DateType</a></span> using the optionally specified format.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R137" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">138</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.trunc.html#pyspark.sql.functions.trunc">trunc</a></span>(date, format)</td><td class="s5" dir="ltr">Returns date truncated to the unit specified by the format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R138" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">139</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_utc_timestamp.html#pyspark.sql.functions.from_utc_timestamp">from_utc_timestamp</a></span>(timestamp, tz)</td><td class="s5" dir="ltr">This is a common function for databases supporting TIMESTAMP WITHOUT TIMEZONE.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R139" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">140</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_utc_timestamp.html#pyspark.sql.functions.to_utc_timestamp">to_utc_timestamp</a></span>(timestamp, tz)</td><td class="s5" dir="ltr">This is a common function for databases supporting TIMESTAMP WITHOUT TIMEZONE.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R140" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">141</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.weekday.html#pyspark.sql.functions.weekday">weekday</a></span>(col)</td><td class="s5" dir="ltr">Returns the day of the week for date/timestamp (0 = Monday, 1 = Tuesday, …, 6 = Sunday).</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R141" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">142</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.window.html#pyspark.sql.functions.window">window</a></span>(timeColumn, windowDuration[, …])</td><td class="s5" dir="ltr">Bucketize rows into one or more time windows given a timestamp specifying column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R142" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">143</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.session_window.html#pyspark.sql.functions.session_window">session_window</a></span>(timeColumn, gapDuration)</td><td class="s5" dir="ltr">Generates session window given a timestamp specifying column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R143" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">144</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.timestamp_micros.html#pyspark.sql.functions.timestamp_micros">timestamp_micros</a></span>(col)</td><td class="s5" dir="ltr">Creates timestamp from the number of microseconds since UTC epoch.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R144" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">145</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.timestamp_millis.html#pyspark.sql.functions.timestamp_millis">timestamp_millis</a></span>(col)</td><td class="s5" dir="ltr">Creates timestamp from the number of milliseconds since UTC epoch.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R145" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">146</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.timestamp_seconds.html#pyspark.sql.functions.timestamp_seconds">timestamp_seconds</a></span>(col)</td><td class="s5" dir="ltr">Converts the number of seconds from the Unix epoch (1970-01-01T00:00:00Z) to a timestamp.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R146" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">147</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_to_timestamp.html#pyspark.sql.functions.try_to_timestamp">try_to_timestamp</a></span>(col[, format])</td><td class="s5" dir="ltr">Parses the col with the format to a timestamp.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R147" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">148</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_date.html#pyspark.sql.functions.unix_date">unix_date</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of days since 1970-01-01.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R148" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">149</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_micros.html#pyspark.sql.functions.unix_micros">unix_micros</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of microseconds since 1970-01-01 00:00:00 UTC.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R149" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">150</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_millis.html#pyspark.sql.functions.unix_millis">unix_millis</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of milliseconds since 1970-01-01 00:00:00 UTC.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R150" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">151</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_seconds.html#pyspark.sql.functions.unix_seconds">unix_seconds</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of seconds since 1970-01-01 00:00:00 UTC.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R151" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">152</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.window_time.html#pyspark.sql.functions.window_time">window_time</a></span>(windowColumn)</td><td class="s5" dir="ltr">Computes the event time from a window column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R152" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">153</div></th><td class="s4" dir="ltr" colspan="3">Collection Functions</td></tr><tr style="height: 20px"><th id="1474227261R153" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">154</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array.html#pyspark.sql.functions.array">array</a></span>(*cols)</td><td class="s5" dir="ltr">Creates a new array column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R154" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">155</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_contains.html#pyspark.sql.functions.array_contains">array_contains</a></span>(col, value)</td><td class="s5" dir="ltr">Collection function: returns null if the array is null, true if the array contains the given value, and false otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R155" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">156</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.arrays_overlap.html#pyspark.sql.functions.arrays_overlap">arrays_overlap</a></span>(a1, a2)</td><td class="s5" dir="ltr">Collection function: returns true if the arrays contain any common non-null element; if not, returns null if both the arrays are non-empty and any of them contains a null element; returns false otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R156" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">157</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_join.html#pyspark.sql.functions.array_join">array_join</a></span>(col, delimiter[, null_replacement])</td><td class="s5" dir="ltr">Concatenates the elements of column using the delimiter.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R157" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">158</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.create_map.html#pyspark.sql.functions.create_map">create_map</a></span>(*cols)</td><td class="s5" dir="ltr">Creates a new map column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R158" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">159</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.slice.html#pyspark.sql.functions.slice">slice</a></span>(x, start, length)</td><td class="s5" dir="ltr">Collection function: returns an array containing all the elements in x from index start (array indices start at 1, or from the end if start is negative) with the specified length.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R159" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">160</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat.html#pyspark.sql.functions.concat">concat</a></span>(*cols)</td><td class="s5" dir="ltr">Concatenates multiple input columns together into a single column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R160" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">161</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_position.html#pyspark.sql.functions.array_position">array_position</a></span>(col, value)</td><td class="s5" dir="ltr">Collection function: Locates the position of the first occurrence of the given value in the given array.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R161" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">162</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.element_at.html#pyspark.sql.functions.element_at">element_at</a></span>(col, extraction)</td><td class="s5" dir="ltr">Collection function: Returns element of array at given index in extraction if col is array.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R162" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">163</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_append.html#pyspark.sql.functions.array_append">array_append</a></span>(col, value)</td><td class="s5" dir="ltr">Collection function: returns an array of the elements in col1 along with the added element in col2 at the last of the array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R163" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">164</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_size.html#pyspark.sql.functions.array_size">array_size</a></span>(col)</td><td class="s5" dir="ltr">Returns the total number of elements in the array.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R164" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">165</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_sort.html#pyspark.sql.functions.array_sort">array_sort</a></span>(col[, comparator])</td><td class="s5" dir="ltr">Collection function: sorts the input array in ascending order.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R165" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">166</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_insert.html#pyspark.sql.functions.array_insert">array_insert</a></span>(arr, pos, value)</td><td class="s5" dir="ltr">Collection function: adds an item into a given array at a specified array index.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R166" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">167</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_remove.html#pyspark.sql.functions.array_remove">array_remove</a></span>(col, element)</td><td class="s5" dir="ltr">Collection function: Remove all elements that equal to element from the given array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R167" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">168</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_prepend.html#pyspark.sql.functions.array_prepend">array_prepend</a></span>(col, value)</td><td class="s5" dir="ltr">Collection function: Returns an array containing element as well as all elements from array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R168" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">169</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_distinct.html#pyspark.sql.functions.array_distinct">array_distinct</a></span>(col)</td><td class="s5" dir="ltr">Collection function: removes duplicate values from the array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R169" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">170</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_intersect.html#pyspark.sql.functions.array_intersect">array_intersect</a></span>(col1, col2)</td><td class="s5" dir="ltr">Collection function: returns an array of the elements in the intersection of col1 and col2, without duplicates.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R170" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">171</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_union.html#pyspark.sql.functions.array_union">array_union</a></span>(col1, col2)</td><td class="s5" dir="ltr">Collection function: returns an array of the elements in the union of col1 and col2, without duplicates.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R171" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">172</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_except.html#pyspark.sql.functions.array_except">array_except</a></span>(col1, col2)</td><td class="s5" dir="ltr">Collection function: returns an array of the elements in col1 but not in col2, without duplicates.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R172" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">173</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_compact.html#pyspark.sql.functions.array_compact">array_compact</a></span>(col)</td><td class="s5" dir="ltr">Collection function: removes null values from the array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R173" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">174</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.transform.html#pyspark.sql.functions.transform">transform</a></span>(col, f)</td><td class="s5" dir="ltr">Returns an array of elements after applying a transformation to each element in the input array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R174" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">175</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.exists.html#pyspark.sql.functions.exists">exists</a></span>(col, f)</td><td class="s5" dir="ltr">Returns whether a predicate holds for one or more elements in the array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R175" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">176</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.forall.html#pyspark.sql.functions.forall">forall</a></span>(col, f)</td><td class="s5" dir="ltr">Returns whether a predicate holds for every element in the array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R176" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">177</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.filter.html#pyspark.sql.functions.filter">filter</a></span>(col, f)</td><td class="s5" dir="ltr">Returns an array of elements for which a predicate holds in a given array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R177" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">178</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.aggregate.html#pyspark.sql.functions.aggregate">aggregate</a></span>(col, initialValue, merge[, finish])</td><td class="s5" dir="ltr">Applies a binary operator to an initial state and all elements in the array, and reduces this to a single state.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R178" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">179</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.zip_with.html#pyspark.sql.functions.zip_with">zip_with</a></span>(left, right, f)</td><td class="s5" dir="ltr">Merge two given arrays, element-wise, into a single array using a function.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R179" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">180</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.transform_keys.html#pyspark.sql.functions.transform_keys">transform_keys</a></span>(col, f)</td><td class="s5" dir="ltr">Applies a function to every key-value pair in a map and returns a map with the results of those applications as the new keys for the pairs.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R180" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">181</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.transform_values.html#pyspark.sql.functions.transform_values">transform_values</a></span>(col, f)</td><td class="s5" dir="ltr">Applies a function to every key-value pair in a map and returns a map with the results of those applications as the new values for the pairs.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R181" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">182</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_filter.html#pyspark.sql.functions.map_filter">map_filter</a></span>(col, f)</td><td class="s5" dir="ltr">Returns a map whose key-value pairs satisfy a predicate.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R182" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">183</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_from_arrays.html#pyspark.sql.functions.map_from_arrays">map_from_arrays</a></span>(col1, col2)</td><td class="s5" dir="ltr">Creates a new map from two arrays.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R183" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">184</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_zip_with.html#pyspark.sql.functions.map_zip_with">map_zip_with</a></span>(col1, col2, f)</td><td class="s5" dir="ltr">Merge two given maps, key-wise into a single map using a function.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R184" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">185</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html#pyspark.sql.functions.explode">explode</a></span>(col)</td><td class="s5" dir="ltr">Returns a new row for each element in the given array or map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R185" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">186</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode_outer.html#pyspark.sql.functions.explode_outer">explode_outer</a></span>(col)</td><td class="s5" dir="ltr">Returns a new row for each element in the given array or map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R186" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">187</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.posexplode.html#pyspark.sql.functions.posexplode">posexplode</a></span>(col)</td><td class="s5" dir="ltr">Returns a new row for each element with position in the given array or map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R187" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">188</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.posexplode_outer.html#pyspark.sql.functions.posexplode_outer">posexplode_outer</a></span>(col)</td><td class="s5" dir="ltr">Returns a new row for each element with position in the given array or map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R188" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">189</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.inline.html#pyspark.sql.functions.inline">inline</a></span>(col)</td><td class="s5" dir="ltr">Explodes an array of structs into a table.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R189" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">190</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.inline_outer.html#pyspark.sql.functions.inline_outer">inline_outer</a></span>(col)</td><td class="s5" dir="ltr">Explodes an array of structs into a table.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R190" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">191</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.get.html#pyspark.sql.functions.get">get</a></span>(col, index)</td><td class="s5" dir="ltr">Collection function: Returns element of array at given (0-based) index.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R191" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">192</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.get_json_object.html#pyspark.sql.functions.get_json_object">get_json_object</a></span>(col, path)</td><td class="s5" dir="ltr">Extracts json object from a json string based on json path specified, and returns json string of the extracted json object.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R192" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">193</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.json_tuple.html#pyspark.sql.functions.json_tuple">json_tuple</a></span>(col, *fields)</td><td class="s5" dir="ltr">Creates a new row for a json column according to the given field names.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R193" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">194</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_json.html#pyspark.sql.functions.from_json">from_json</a></span>(col, schema[, options])</td><td class="s5" dir="ltr">Parses a column containing a JSON string into a MapType with StringType as keys type, StructType or ArrayType with the specified schema.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R194" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">195</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.schema_of_json.html#pyspark.sql.functions.schema_of_json">schema_of_json</a></span>(json[, options])</td><td class="s5" dir="ltr">Parses a JSON string and infers its schema in DDL format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R195" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">196</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_json.html#pyspark.sql.functions.to_json">to_json</a></span>(col[, options])</td><td class="s5" dir="ltr">Converts a column containing a StructType, ArrayType or a MapType into a JSON string.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R196" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">197</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.json_array_length.html#pyspark.sql.functions.json_array_length">json_array_length</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of elements in the outermost JSON array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R197" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">198</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.json_object_keys.html#pyspark.sql.functions.json_object_keys">json_object_keys</a></span>(col)</td><td class="s5" dir="ltr">Returns all the keys of the outermost JSON object as an array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R198" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">199</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.size.html#pyspark.sql.functions.size">size</a></span>(col)</td><td class="s5" dir="ltr">Collection function: returns the length of the array or map stored in the column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R199" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">200</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cardinality.html#pyspark.sql.functions.cardinality">cardinality</a></span>(col)</td><td class="s5" dir="ltr">Collection function: returns the length of the array or map stored in the column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R200" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">201</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.struct.html#pyspark.sql.functions.struct">struct</a></span>(*cols)</td><td class="s5" dir="ltr">Creates a new struct column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R201" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">202</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sort_array.html#pyspark.sql.functions.sort_array">sort_array</a></span>(col[, asc])</td><td class="s5" dir="ltr">Collection function: sorts the input array in ascending or descending order according to the natural ordering of the array elements.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R202" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">203</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_max.html#pyspark.sql.functions.array_max">array_max</a></span>(col)</td><td class="s5" dir="ltr">Collection function: returns the maximum value of the array.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R203" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">204</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_min.html#pyspark.sql.functions.array_min">array_min</a></span>(col)</td><td class="s5" dir="ltr">Collection function: returns the minimum value of the array.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R204" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">205</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.shuffle.html#pyspark.sql.functions.shuffle">shuffle</a></span>(col)</td><td class="s5" dir="ltr">Collection function: Generates a random permutation of the given array.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R205" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">206</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.reverse.html#pyspark.sql.functions.reverse">reverse</a></span>(col)</td><td class="s5" dir="ltr">Collection function: returns a reversed string or an array with reverse order of elements.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R206" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">207</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.flatten.html#pyspark.sql.functions.flatten">flatten</a></span>(col)</td><td class="s5" dir="ltr">Collection function: creates a single array from an array of arrays.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R207" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">208</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sequence.html#pyspark.sql.functions.sequence">sequence</a></span>(start, stop[, step])</td><td class="s5" dir="ltr">Generate a sequence of integers from start to stop, incrementing by step.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R208" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">209</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_repeat.html#pyspark.sql.functions.array_repeat">array_repeat</a></span>(col, count)</td><td class="s5" dir="ltr">Collection function: creates an array containing a column repeated count times.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R209" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">210</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_contains_key.html#pyspark.sql.functions.map_contains_key">map_contains_key</a></span>(col, value)</td><td class="s5" dir="ltr">Returns true if the map contains the key.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R210" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">211</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_keys.html#pyspark.sql.functions.map_keys">map_keys</a></span>(col)</td><td class="s5" dir="ltr">Collection function: Returns an unordered array containing the keys of the map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R211" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">212</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_values.html#pyspark.sql.functions.map_values">map_values</a></span>(col)</td><td class="s5" dir="ltr">Collection function: Returns an unordered array containing the values of the map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R212" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">213</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_entries.html#pyspark.sql.functions.map_entries">map_entries</a></span>(col)</td><td class="s5" dir="ltr">Collection function: Returns an unordered array of all entries in the given map.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R213" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">214</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_from_entries.html#pyspark.sql.functions.map_from_entries">map_from_entries</a></span>(col)</td><td class="s5" dir="ltr">Collection function: Converts an array of entries (key value struct types) to a map of values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R214" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">215</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.arrays_zip.html#pyspark.sql.functions.arrays_zip">arrays_zip</a></span>(*cols)</td><td class="s5" dir="ltr">Collection function: Returns a merged array of structs in which the N-th struct contains all N-th values of input arrays.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R215" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">216</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.map_concat.html#pyspark.sql.functions.map_concat">map_concat</a></span>(*cols)</td><td class="s5" dir="ltr">Returns the union of all the given maps.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R216" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">217</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_csv.html#pyspark.sql.functions.from_csv">from_csv</a></span>(col, schema[, options])</td><td class="s5" dir="ltr">Parses a column containing a CSV string to a row with the specified schema.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R217" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">218</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.schema_of_csv.html#pyspark.sql.functions.schema_of_csv">schema_of_csv</a></span>(csv[, options])</td><td class="s5" dir="ltr">Parses a CSV string and infers its schema in DDL format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R218" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">219</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.str_to_map.html#pyspark.sql.functions.str_to_map">str_to_map</a></span>(text[, pairDelim, keyValueDelim])</td><td class="s5" dir="ltr">Creates a map after splitting the text into key/value pairs using delimiters.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R219" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">220</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_csv.html#pyspark.sql.functions.to_csv">to_csv</a></span>(col[, options])</td><td class="s5" dir="ltr">Converts a column containing a StructType into a CSV string.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R220" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">221</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_element_at.html#pyspark.sql.functions.try_element_at">try_element_at</a></span>(col, extraction)</td><td class="s5" dir="ltr">(array, index) - Returns element of array at given (1-based) index.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R221" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">222</div></th><td class="s4" dir="ltr" colspan="3">Partition Transformation Functions</td></tr><tr style="height: 20px"><th id="1474227261R222" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">223</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.years.html#pyspark.sql.functions.years">years</a></span>(col)</td><td class="s5" dir="ltr">Partition transform function: A transform for timestamps and dates to partition data into years.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R223" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">224</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.months.html#pyspark.sql.functions.months">months</a></span>(col)</td><td class="s5" dir="ltr">Partition transform function: A transform for timestamps and dates to partition data into months.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R224" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">225</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.days.html#pyspark.sql.functions.days">days</a></span>(col)</td><td class="s5" dir="ltr">Partition transform function: A transform for timestamps and dates to partition data into days.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R225" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">226</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hours.html#pyspark.sql.functions.hours">hours</a></span>(col)</td><td class="s5" dir="ltr">Partition transform function: A transform for timestamps to partition data into hours.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R226" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">227</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bucket.html#pyspark.sql.functions.bucket">bucket</a></span>(numBuckets, col)</td><td class="s5" dir="ltr">Partition transform function: A transform for any type that partitions by a hash of the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R227" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">228</div></th><td class="s4" dir="ltr" colspan="3">Aggregate Functions</td></tr><tr style="height: 20px"><th id="1474227261R228" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">229</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.any_value.html#pyspark.sql.functions.any_value">any_value</a></span>(col[, ignoreNulls])</td><td class="s5" dir="ltr">Returns some value of col for a group of rows.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R229" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">230</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.approxCountDistinct.html#pyspark.sql.functions.approxCountDistinct">approxCountDistinct</a></span>(col[, rsd])</td><td class="s5" dir="ltr">New in version 1.3.0.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R230" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">231</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.approx_count_distinct.html#pyspark.sql.functions.approx_count_distinct">approx_count_distinct</a></span>(col[, rsd])</td><td class="s5" dir="ltr">Aggregate function: returns a new <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> for approximate distinct count of column col.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R231" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">232</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.approx_percentile.html#pyspark.sql.functions.approx_percentile">approx_percentile</a></span>(col, percentage[, accuracy])</td><td class="s5" dir="ltr">Returns the approximate percentile of the numeric column col which is the smallest value in the ordered col values (sorted from least to greatest) such that no more than percentage of col values is less than the value or equal to that value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R232" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">233</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.array_agg.html#pyspark.sql.functions.array_agg">array_agg</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns a list of objects with duplicates.</td><td class="s6" dir="ltr">si</td></tr><tr style="height: 20px"><th id="1474227261R233" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">234</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.avg.html#pyspark.sql.functions.avg">avg</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the average of the values in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R234" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">235</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_and.html#pyspark.sql.functions.bit_and">bit_and</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the bitwise AND of all non-null input values, or null if none.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R235" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">236</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_or.html#pyspark.sql.functions.bit_or">bit_or</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the bitwise OR of all non-null input values, or null if none.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R236" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">237</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_xor.html#pyspark.sql.functions.bit_xor">bit_xor</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the bitwise XOR of all non-null input values, or null if none.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R237" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">238</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bool_and.html#pyspark.sql.functions.bool_and">bool_and</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns true if all values of col are true.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R238" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">239</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bool_or.html#pyspark.sql.functions.bool_or">bool_or</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns true if at least one value of col is true.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R239" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">240</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_list.html#pyspark.sql.functions.collect_list">collect_list</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns a list of objects with duplicates.</td><td class="s6" dir="ltr">si</td></tr><tr style="height: 20px"><th id="1474227261R240" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">241</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_set.html#pyspark.sql.functions.collect_set">collect_set</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns a set of objects with duplicate elements eliminated.</td><td class="s6" dir="ltr">si</td></tr><tr style="height: 20px"><th id="1474227261R241" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">242</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.corr.html#pyspark.sql.functions.corr">corr</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns a new <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> for the Pearson Correlation Coefficient for col1 and col2.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R242" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">243</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count.html#pyspark.sql.functions.count">count</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the number of items in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R243" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">244</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count_distinct.html#pyspark.sql.functions.count_distinct">count_distinct</a></span>(col, *cols)</td><td class="s5" dir="ltr">Returns a new Column for distinct count of col or cols.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R244" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">245</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.countDistinct.html#pyspark.sql.functions.countDistinct">countDistinct</a></span>(col, *cols)</td><td class="s5" dir="ltr">Returns a new <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> for distinct count of col or cols.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R245" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">246</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count_min_sketch.html#pyspark.sql.functions.count_min_sketch">count_min_sketch</a></span>(col, eps, confidence, seed)</td><td class="s5" dir="ltr">Returns a count-min sketch of a column with the given esp, confidence and seed.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R246" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">247</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count_if.html#pyspark.sql.functions.count_if">count_if</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of TRUE values for the col.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R247" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">248</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.covar_pop.html#pyspark.sql.functions.covar_pop">covar_pop</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns a new <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> for the population covariance of col1 and col2.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R248" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">249</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.covar_samp.html#pyspark.sql.functions.covar_samp">covar_samp</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns a new <span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html#pyspark.sql.Column">Column</a></span> for the sample covariance of col1 and col2.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R249" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">250</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.every.html#pyspark.sql.functions.every">every</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns true if all values of col are true.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R250" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">251</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.first.html#pyspark.sql.functions.first">first</a></span>(col[, ignorenulls])</td><td class="s5" dir="ltr">Aggregate function: returns the first value in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R251" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">252</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.first_value.html#pyspark.sql.functions.first_value">first_value</a></span>(col[, ignoreNulls])</td><td class="s5" dir="ltr">Returns the first value of col for a group of rows.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R252" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">253</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.grouping.html#pyspark.sql.functions.grouping">grouping</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: indicates whether a specified column in a GROUP BY list is aggregated or not, returns 1 for aggregated or 0 for not aggregated in the result set.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R253" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">254</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.grouping_id.html#pyspark.sql.functions.grouping_id">grouping_id</a></span>(*cols)</td><td class="s5" dir="ltr">Aggregate function: returns the level of grouping, equals to</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R254" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">255</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.histogram_numeric.html#pyspark.sql.functions.histogram_numeric">histogram_numeric</a></span>(col, nBins)</td><td class="s5" dir="ltr">Computes a histogram on numeric ‘col’ using nb bins.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R255" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">256</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hll_sketch_agg.html#pyspark.sql.functions.hll_sketch_agg">hll_sketch_agg</a></span>(col[, lgConfigK])</td><td class="s5" dir="ltr">Aggregate function: returns the updatable binary representation of the Datasketches HllSketch configured with lgConfigK arg.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R256" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">257</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hll_union_agg.html#pyspark.sql.functions.hll_union_agg">hll_union_agg</a></span>(col[, allowDifferentLgConfigK])</td><td class="s5" dir="ltr">Aggregate function: returns the updatable binary representation of the Datasketches HllSketch, generated by merging previously created Datasketches HllSketch instances via a Datasketches Union instance.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R257" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">258</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.kurtosis.html#pyspark.sql.functions.kurtosis">kurtosis</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the kurtosis of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R258" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">259</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.last.html#pyspark.sql.functions.last">last</a></span>(col[, ignorenulls])</td><td class="s5" dir="ltr">Aggregate function: returns the last value in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R259" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">260</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.last_value.html#pyspark.sql.functions.last_value">last_value</a></span>(col[, ignoreNulls])</td><td class="s5" dir="ltr">Returns the last value of col for a group of rows.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R260" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">261</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.max.html#pyspark.sql.functions.max">max</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the maximum value of the expression in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R261" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">262</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.max_by.html#pyspark.sql.functions.max_by">max_by</a></span>(col, ord)</td><td class="s5" dir="ltr">Returns the value associated with the maximum value of ord.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R262" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">263</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.mean.html#pyspark.sql.functions.mean">mean</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the average of the values in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R263" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">264</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.median.html#pyspark.sql.functions.median">median</a></span>(col)</td><td class="s5" dir="ltr">Returns the median of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R264" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">265</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.min.html#pyspark.sql.functions.min">min</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the minimum value of the expression in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R265" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">266</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.min_by.html#pyspark.sql.functions.min_by">min_by</a></span>(col, ord)</td><td class="s5" dir="ltr">Returns the value associated with the minimum value of ord.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R266" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">267</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.mode.html#pyspark.sql.functions.mode">mode</a></span>(col)</td><td class="s5" dir="ltr">Returns the most frequent value in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R267" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">268</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.percentile.html#pyspark.sql.functions.percentile">percentile</a></span>(col, percentage[, frequency])</td><td class="s5" dir="ltr">Returns the exact percentile(s) of numeric column expr at the given percentage(s) with value range in [0.0, 1.0].</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R268" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">269</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.percentile_approx.html#pyspark.sql.functions.percentile_approx">percentile_approx</a></span>(col, percentage[, accuracy])</td><td class="s5" dir="ltr">Returns the approximate percentile of the numeric column col which is the smallest value in the ordered col values (sorted from least to greatest) such that no more than percentage of col values is less than the value or equal to that value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R269" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">270</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.product.html#pyspark.sql.functions.product">product</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the product of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R270" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">271</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.reduce.html#pyspark.sql.functions.reduce">reduce</a></span>(col, initialValue, merge[, finish])</td><td class="s5" dir="ltr">Applies a binary operator to an initial state and all elements in the array, and reduces this to a single state.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R271" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">272</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_avgx.html#pyspark.sql.functions.regr_avgx">regr_avgx</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the average of the independent variable for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R272" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">273</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_avgy.html#pyspark.sql.functions.regr_avgy">regr_avgy</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the average of the dependent variable for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R273" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">274</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_count.html#pyspark.sql.functions.regr_count">regr_count</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the number of non-null number pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R274" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">275</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_intercept.html#pyspark.sql.functions.regr_intercept">regr_intercept</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the intercept of the univariate linear regression line for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R275" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">276</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_r2.html#pyspark.sql.functions.regr_r2">regr_r2</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the coefficient of determination for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R276" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">277</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_slope.html#pyspark.sql.functions.regr_slope">regr_slope</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns the slope of the linear regression line for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R277" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">278</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_sxx.html#pyspark.sql.functions.regr_sxx">regr_sxx</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns REGR_COUNT(y, x) * VAR_POP(x) for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R278" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">279</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_sxy.html#pyspark.sql.functions.regr_sxy">regr_sxy</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns REGR_COUNT(y, x) * COVAR_POP(y, x) for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R279" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">280</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regr_syy.html#pyspark.sql.functions.regr_syy">regr_syy</a></span>(y, x)</td><td class="s5" dir="ltr">Aggregate function: returns REGR_COUNT(y, x) * VAR_POP(y) for non-null pairs in a group, where y is the dependent variable and x is the independent variable.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R280" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">281</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.skewness.html#pyspark.sql.functions.skewness">skewness</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the skewness of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R281" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">282</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.some.html#pyspark.sql.functions.some">some</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns true if at least one value of col is true.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R282" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">283</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.std.html#pyspark.sql.functions.std">std</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: alias for stddev_samp.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R283" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">284</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev.html#pyspark.sql.functions.stddev">stddev</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: alias for stddev_samp.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R284" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">285</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev_pop.html#pyspark.sql.functions.stddev_pop">stddev_pop</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns population standard deviation of the expression in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R285" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">286</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stddev_samp.html#pyspark.sql.functions.stddev_samp">stddev_samp</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the unbiased sample standard deviation of the expression in a group.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R286" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">287</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sum.html#pyspark.sql.functions.sum">sum</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the sum of all values in the expression.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R287" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">288</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sum_distinct.html#pyspark.sql.functions.sum_distinct">sum_distinct</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the sum of distinct values in the expression.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R288" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">289</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sumDistinct.html#pyspark.sql.functions.sumDistinct">sumDistinct</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the sum of distinct values in the expression.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R289" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">290</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.var_pop.html#pyspark.sql.functions.var_pop">var_pop</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the population variance of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R290" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">291</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.var_samp.html#pyspark.sql.functions.var_samp">var_samp</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: returns the unbiased sample variance of the values in a group.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R291" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">292</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.variance.html#pyspark.sql.functions.variance">variance</a></span>(col)</td><td class="s5" dir="ltr">Aggregate function: alias for var_samp</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R292" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">293</div></th><td class="s4" dir="ltr" colspan="3">Window Functions</td></tr><tr style="height: 20px"><th id="1474227261R293" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">294</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.cume_dist.html#pyspark.sql.functions.cume_dist">cume_dist</a></span>()</td><td class="s5" dir="ltr">Window function: returns the cumulative distribution of values within a window partition, i.e.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R294" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">295</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dense_rank.html#pyspark.sql.functions.dense_rank">dense_rank</a></span>()</td><td class="s5" dir="ltr">Window function: returns the rank of rows within a window partition, without any gaps.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R295" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">296</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lag.html#pyspark.sql.functions.lag">lag</a></span>(col[, offset, default])</td><td class="s5" dir="ltr">Window function: returns the value that is offset rows before the current row, and default if there is less than offset rows before the current row.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R296" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">297</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lead.html#pyspark.sql.functions.lead">lead</a></span>(col[, offset, default])</td><td class="s5" dir="ltr">Window function: returns the value that is offset rows after the current row, and default if there is less than offset rows after the current row.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R297" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">298</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.nth_value.html#pyspark.sql.functions.nth_value">nth_value</a></span>(col, offset[, ignoreNulls])</td><td class="s5" dir="ltr">Window function: returns the value that is the offsetth row of the window frame (counting from 1), and null if the size of window frame is less than offset rows.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R298" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">299</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ntile.html#pyspark.sql.functions.ntile">ntile</a></span>(n)</td><td class="s5" dir="ltr">Window function: returns the ntile group id (from 1 to n inclusive) in an ordered window partition.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R299" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">300</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.percent_rank.html#pyspark.sql.functions.percent_rank">percent_rank</a></span>()</td><td class="s5" dir="ltr">Window function: returns the relative rank (i.e.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R300" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">301</div></th><td class="s5" dir="ltr"><span style="text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rank.html#pyspark.sql.functions.rank">rank</a></span>()</td><td class="s5" dir="ltr">Window function: returns the rank of rows within a window partition.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R301" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">302</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.row_number.html#pyspark.sql.functions.row_number">row_number</a></span>()</td><td class="s5" dir="ltr">Window function: returns a sequential number starting at 1 within a window partition.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R302" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">303</div></th><td class="s4" dir="ltr" colspan="3">Sort Functions</td></tr><tr style="height: 20px"><th id="1474227261R303" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">304</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.asc.html#pyspark.sql.functions.asc">asc</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the ascending order of the given column name.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R304" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">305</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.asc_nulls_first.html#pyspark.sql.functions.asc_nulls_first">asc_nulls_first</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the ascending order of the given column name, and null values return before non-null values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R305" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">306</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.asc_nulls_last.html#pyspark.sql.functions.asc_nulls_last">asc_nulls_last</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the ascending order of the given column name, and null values appear after non-null values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R306" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">307</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.desc.html#pyspark.sql.functions.desc">desc</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the descending order of the given column name.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R307" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">308</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.desc_nulls_first.html#pyspark.sql.functions.desc_nulls_first">desc_nulls_first</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the descending order of the given column name, and null values appear before non-null values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R308" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">309</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.desc_nulls_last.html#pyspark.sql.functions.desc_nulls_last">desc_nulls_last</a></span>(col)</td><td class="s5" dir="ltr">Returns a sort expression based on the descending order of the given column name, and null values appear after non-null values.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R309" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">310</div></th><td class="s4" dir="ltr" colspan="3">String Functions</td></tr><tr style="height: 20px"><th id="1474227261R310" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">311</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ascii.html#pyspark.sql.functions.ascii">ascii</a></span>(col)</td><td class="s5" dir="ltr">Computes the numeric value of the first character of the string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R311" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">312</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.base64.html#pyspark.sql.functions.base64">base64</a></span>(col)</td><td class="s5" dir="ltr">Computes the BASE64 encoding of a binary column and returns it as a string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R312" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">313</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_length.html#pyspark.sql.functions.bit_length">bit_length</a></span>(col)</td><td class="s5" dir="ltr">Calculates the bit length for the specified string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R313" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">314</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.btrim.html#pyspark.sql.functions.btrim">btrim</a></span>(str[, trim])</td><td class="s5" dir="ltr">Remove the leading and trailing trim characters from str.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R314" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">315</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.char.html#pyspark.sql.functions.char">char</a></span>(col)</td><td class="s5" dir="ltr">Returns the ASCII character having the binary equivalent to col.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R315" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">316</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.character_length.html#pyspark.sql.functions.character_length">character_length</a></span>(str)</td><td class="s5" dir="ltr">Returns the character length of string data or number of bytes of binary data.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R316" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">317</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.char_length.html#pyspark.sql.functions.char_length">char_length</a></span>(str)</td><td class="s5" dir="ltr">Returns the character length of string data or number of bytes of binary data.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R317" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">318</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat_ws.html#pyspark.sql.functions.concat_ws">concat_ws</a></span>(sep, *cols)</td><td class="s5" dir="ltr">Concatenates multiple input string columns together into a single string column, using the given separator.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R318" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">319</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.contains.html#pyspark.sql.functions.contains">contains</a></span>(left, right)</td><td class="s5" dir="ltr">Returns a boolean.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R319" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">320</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.decode.html#pyspark.sql.functions.decode">decode</a></span>(col, charset)</td><td class="s5" dir="ltr">Computes the first argument into a string from a binary using the provided character set (one of ‘US-ASCII’, ‘ISO-8859-1’, ‘UTF-8’, ‘UTF-16BE’, ‘UTF-16LE’, ‘UTF-16’).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R320" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">321</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.elt.html#pyspark.sql.functions.elt">elt</a></span>(*inputs)</td><td class="s5" dir="ltr">Returns the n-th input, e.g., returns input2 when n is 2.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R321" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">322</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.encode.html#pyspark.sql.functions.encode">encode</a></span>(col, charset)</td><td class="s5" dir="ltr">Computes the first argument into a binary from a string using the provided character set (one of ‘US-ASCII’, ‘ISO-8859-1’, ‘UTF-8’, ‘UTF-16BE’, ‘UTF-16LE’, ‘UTF-16’).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R322" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">323</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.endswith.html#pyspark.sql.functions.endswith">endswith</a></span>(str, suffix)</td><td class="s5" dir="ltr">Returns a boolean.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R323" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">324</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.find_in_set.html#pyspark.sql.functions.find_in_set">find_in_set</a></span>(str, str_array)</td><td class="s5" dir="ltr">Returns the index (1-based) of the given string (str) in the comma-delimited list (strArray).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R324" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">325</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.format_number.html#pyspark.sql.functions.format_number">format_number</a></span>(col, d)</td><td class="s5" dir="ltr">Formats the number X to a format like ‘#,–#,–#.–’, rounded to d decimal places with HALF_EVEN round mode, and returns the result as a string.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R325" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">326</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.format_string.html#pyspark.sql.functions.format_string">format_string</a></span>(format, *cols)</td><td class="s5" dir="ltr">Formats the arguments in printf-style and returns the result as a string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R326" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">327</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ilike.html#pyspark.sql.functions.ilike">ilike</a></span>(str, pattern[, escapeChar])</td><td class="s5" dir="ltr">Returns true if str matches pattern with escape case-insensitively, null if any arguments are null, false otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R327" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">328</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.initcap.html#pyspark.sql.functions.initcap">initcap</a></span>(col)</td><td class="s5" dir="ltr">Translate the first letter of each word to upper case in the sentence.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R328" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">329</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.instr.html#pyspark.sql.functions.instr">instr</a></span>(str, substr)</td><td class="s5" dir="ltr">Locate the position of the first occurrence of substr column in the given string.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R329" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">330</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lcase.html#pyspark.sql.functions.lcase">lcase</a></span>(str)</td><td class="s5" dir="ltr">Returns str with all characters changed to lowercase.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R330" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">331</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.length.html#pyspark.sql.functions.length">length</a></span>(col)</td><td class="s5" dir="ltr">Computes the character length of string data or number of bytes of binary data.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R331" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">332</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.like.html#pyspark.sql.functions.like">like</a></span>(str, pattern[, escapeChar])</td><td class="s5" dir="ltr">Returns true if str matches pattern with escape, null if any arguments are null, false otherwise.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R332" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">333</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lower.html#pyspark.sql.functions.lower">lower</a></span>(col)</td><td class="s5" dir="ltr">Converts a string expression to lower case.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R333" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">334</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.left.html#pyspark.sql.functions.left">left</a></span>(str, len)</td><td class="s5" dir="ltr">Returns the leftmost len`(`len can be string type) characters from the string str, if len is less or equal than 0 the result is an empty string.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R334" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">335</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.levenshtein.html#pyspark.sql.functions.levenshtein">levenshtein</a></span>(left, right[, threshold])</td><td class="s5" dir="ltr">Computes the Levenshtein distance of the two given strings.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R335" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">336</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.locate.html#pyspark.sql.functions.locate">locate</a></span>(substr, str[, pos])</td><td class="s5" dir="ltr">Locate the position of the first occurrence of substr in a string column, after position pos.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R336" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">337</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lpad.html#pyspark.sql.functions.lpad">lpad</a></span>(col, len, pad)</td><td class="s5" dir="ltr">Left-pad the string column to width len with pad.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R337" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">338</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ltrim.html#pyspark.sql.functions.ltrim">ltrim</a></span>(col)</td><td class="s5" dir="ltr">Trim the spaces from left end for the specified string value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R338" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">339</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.mask.html#pyspark.sql.functions.mask">mask</a></span>(col[, upperChar, lowerChar, digitChar, …])</td><td class="s5" dir="ltr">Masks the given string value.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R339" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">340</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.octet_length.html#pyspark.sql.functions.octet_length">octet_length</a></span>(col)</td><td class="s5" dir="ltr">Calculates the byte length for the specified string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R340" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">341</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.parse_url.html#pyspark.sql.functions.parse_url">parse_url</a></span>(url, partToExtract[, key])</td><td class="s5" dir="ltr">Extracts a part from a URL.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R341" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">342</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.position.html#pyspark.sql.functions.position">position</a></span>(substr, str[, start])</td><td class="s5" dir="ltr">Returns the position of the first occurrence of substr in str after position start.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R342" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">343</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.printf.html#pyspark.sql.functions.printf">printf</a></span>(format, *cols)</td><td class="s5" dir="ltr">Formats the arguments in printf-style and returns the result as a string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R343" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">344</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rlike.html#pyspark.sql.functions.rlike">rlike</a></span>(str, regexp)</td><td class="s5" dir="ltr">Returns true if str matches the Java regex regexp, or false otherwise.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R344" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">345</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp.html#pyspark.sql.functions.regexp">regexp</a></span>(str, regexp)</td><td class="s5" dir="ltr">Returns true if str matches the Java regex regexp, or false otherwise.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R345" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">346</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_like.html#pyspark.sql.functions.regexp_like">regexp_like</a></span>(str, regexp)</td><td class="s5" dir="ltr">Returns true if str matches the Java regex regexp, or false otherwise.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R346" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">347</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_count.html#pyspark.sql.functions.regexp_count">regexp_count</a></span>(str, regexp)</td><td class="s5" dir="ltr">Returns a count of the number of times that the Java regex pattern regexp is matched in the string str.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R347" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">348</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract.html#pyspark.sql.functions.regexp_extract">regexp_extract</a></span>(str, pattern, idx)</td><td class="s5" dir="ltr">Extract a specific group matched by the Java regex regexp, from the specified string column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R348" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">349</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract_all.html#pyspark.sql.functions.regexp_extract_all">regexp_extract_all</a></span>(str, regexp[, idx])</td><td class="s5" dir="ltr">Extract all strings in the str that match the Java regex regexp and corresponding to the regex group index.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R349" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">350</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_replace.html#pyspark.sql.functions.regexp_replace">regexp_replace</a></span>(string, pattern, replacement)</td><td class="s5" dir="ltr">Replace all substrings of the specified string value that match regexp with replacement.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R350" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">351</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_substr.html#pyspark.sql.functions.regexp_substr">regexp_substr</a></span>(str, regexp)</td><td class="s5" dir="ltr">Returns the substring that matches the Java regex regexp within the string str.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R351" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">352</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_instr.html#pyspark.sql.functions.regexp_instr">regexp_instr</a></span>(str, regexp[, idx])</td><td class="s5" dir="ltr">Extract all strings in the str that match the Java regex regexp and corresponding to the regex group index.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R352" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">353</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.replace.html#pyspark.sql.functions.replace">replace</a></span>(src, search[, replace])</td><td class="s5" dir="ltr">Replaces all occurrences of search with replace.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R353" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">354</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.right.html#pyspark.sql.functions.right">right</a></span>(str, len)</td><td class="s5" dir="ltr">Returns the rightmost len`(`len can be string type) characters from the string str, if len is less or equal than 0 the result is an empty string.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R354" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">355</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ucase.html#pyspark.sql.functions.ucase">ucase</a></span>(str)</td><td class="s5" dir="ltr">Returns str with all characters changed to uppercase.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R355" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">356</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unbase64.html#pyspark.sql.functions.unbase64">unbase64</a></span>(col)</td><td class="s5" dir="ltr">Decodes a BASE64 encoded string column and returns it as a binary column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R356" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">357</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rpad.html#pyspark.sql.functions.rpad">rpad</a></span>(col, len, pad)</td><td class="s5" dir="ltr">Right-pad the string column to width len with pad.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R357" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">358</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.repeat.html#pyspark.sql.functions.repeat">repeat</a></span>(col, n)</td><td class="s5" dir="ltr">Repeats a string column n times, and returns it as a new string column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R358" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">359</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rtrim.html#pyspark.sql.functions.rtrim">rtrim</a></span>(col)</td><td class="s5" dir="ltr">Trim the spaces from right end for the specified string value.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R359" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">360</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.soundex.html#pyspark.sql.functions.soundex">soundex</a></span>(col)</td><td class="s5" dir="ltr">Returns the SoundEx encoding for a string</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R360" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">361</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.split.html#pyspark.sql.functions.split">split</a></span>(str, pattern[, limit])</td><td class="s5" dir="ltr">Splits str around matches of the given pattern.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R361" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">362</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.split_part.html#pyspark.sql.functions.split_part">split_part</a></span>(src, delimiter, partNum)</td><td class="s5" dir="ltr">Splits str by delimiter and return requested part of the split (1-based).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R362" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">363</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.startswith.html#pyspark.sql.functions.startswith">startswith</a></span>(str, prefix)</td><td class="s5" dir="ltr">Returns a boolean.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R363" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">364</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.substr.html#pyspark.sql.functions.substr">substr</a></span>(str, pos[, len])</td><td class="s5" dir="ltr">Returns the substring of str that starts at pos and is of length len, or the slice of byte array that starts at pos and is of length len.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R364" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">365</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.substring.html#pyspark.sql.functions.substring">substring</a></span>(str, pos, len)</td><td class="s5" dir="ltr">Substring starts at pos and is of length len when str is String type or returns the slice of byte array that starts at pos in byte and is of length len when str is Binary type.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R365" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">366</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.substring_index.html#pyspark.sql.functions.substring_index">substring_index</a></span>(str, delim, count)</td><td class="s5" dir="ltr">Returns the substring from string str before count occurrences of the delimiter delim.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R366" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">367</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.overlay.html#pyspark.sql.functions.overlay">overlay</a></span>(src, replace, pos[, len])</td><td class="s5" dir="ltr">Overlay the specified portion of src with replace, starting from byte position pos of src and proceeding for len bytes.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R367" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">368</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sentences.html#pyspark.sql.functions.sentences">sentences</a></span>(string[, language, country])</td><td class="s5" dir="ltr">Splits a string into arrays of sentences, where each sentence is an array of words.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R368" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">369</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_binary.html#pyspark.sql.functions.to_binary">to_binary</a></span>(col[, format])</td><td class="s5" dir="ltr">Converts the input col to a binary value based on the supplied format.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R369" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">370</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_char.html#pyspark.sql.functions.to_char">to_char</a></span>(col, format)</td><td class="s5" dir="ltr">Convert col to a string based on the format.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R370" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">371</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_number.html#pyspark.sql.functions.to_number">to_number</a></span>(col, format)</td><td class="s5" dir="ltr">Convert string ‘col’ to a number based on the string format ‘format’.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R371" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">372</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_varchar.html#pyspark.sql.functions.to_varchar">to_varchar</a></span>(col, format)</td><td class="s5" dir="ltr">Convert col to a string based on the format.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R372" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">373</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.translate.html#pyspark.sql.functions.translate">translate</a></span>(srcCol, matching, replace)</td><td class="s5" dir="ltr">A function translate any character in the srcCol by a character in matching.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R373" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">374</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.trim.html#pyspark.sql.functions.trim">trim</a></span>(col)</td><td class="s5" dir="ltr">Trim the spaces from both ends for the specified string column.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R374" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">375</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.upper.html#pyspark.sql.functions.upper">upper</a></span>(col)</td><td class="s5" dir="ltr">Converts a string expression to upper case.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R375" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">376</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.url_decode.html#pyspark.sql.functions.url_decode">url_decode</a></span>(str)</td><td class="s5" dir="ltr">Decodes a str in ‘application/x-www-form-urlencoded’ format using a specific encoding scheme.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R376" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">377</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.url_encode.html#pyspark.sql.functions.url_encode">url_encode</a></span>(str)</td><td class="s5" dir="ltr">Translates a string into ‘application/x-www-form-urlencoded’ format using a specific encoding scheme.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R377" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">378</div></th><td class="s4" dir="ltr" colspan="3">Bitwise Functions</td></tr><tr style="height: 20px"><th id="1474227261R378" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">379</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_count.html#pyspark.sql.functions.bit_count">bit_count</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of bits that are set in the argument expr as an unsigned 64-bit integer, or NULL if the argument is NULL.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R379" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">380</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bit_get.html#pyspark.sql.functions.bit_get">bit_get</a></span>(col, pos)</td><td class="s5" dir="ltr">Returns the value of the bit (0 or 1) at the specified position.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R380" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">381</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.getbit.html#pyspark.sql.functions.getbit">getbit</a></span>(col, pos)</td><td class="s5" dir="ltr">Returns the value of the bit (0 or 1) at the specified position.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R381" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">382</div></th><td class="s4" dir="ltr" colspan="3">Call Functions</td></tr><tr style="height: 20px"><th id="1474227261R382" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">383</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.call_function.html#pyspark.sql.functions.call_function">call_function</a></span>(funcName, *cols)</td><td class="s5" dir="ltr">Call a SQL function.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R383" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">384</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.call_udf.html#pyspark.sql.functions.call_udf">call_udf</a></span>(udfName, *cols)</td><td class="s5" dir="ltr">Call an user-defined function.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R384" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">385</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html#pyspark.sql.functions.pandas_udf">pandas_udf</a></span>([f, returnType, functionType])</td><td class="s5" dir="ltr">Creates a pandas user defined function (a.k.a.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R385" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">386</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html#pyspark.sql.functions.udf">udf</a></span>([f, returnType, useArrow])</td><td class="s5" dir="ltr">Creates a user defined function (UDF).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R386" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">387</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udtf.html#pyspark.sql.functions.udtf">udtf</a></span>([cls, useArrow])</td><td class="s5" dir="ltr">Creates a user defined table function (UDTF).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R387" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">388</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unwrap_udt.html#pyspark.sql.functions.unwrap_udt">unwrap_udt</a></span>(col)</td><td class="s5" dir="ltr">Unwrap UDT data type column into its underlying type.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R388" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">389</div></th><td class="s4" dir="ltr" colspan="3">Misc Functions</td></tr><tr style="height: 20px"><th id="1474227261R389" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">390</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.aes_decrypt.html#pyspark.sql.functions.aes_decrypt">aes_decrypt</a></span>(input, key[, mode, padding, aad])</td><td class="s5" dir="ltr">Returns a decrypted value of input using AES in mode with padding.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R390" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">391</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.aes_encrypt.html#pyspark.sql.functions.aes_encrypt">aes_encrypt</a></span>(input, key[, mode, padding, iv, aad])</td><td class="s5" dir="ltr">Returns an encrypted value of input using AES in given mode with the specified padding.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R391" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">392</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitmap_bit_position.html#pyspark.sql.functions.bitmap_bit_position">bitmap_bit_position</a></span>(col)</td><td class="s5" dir="ltr">Returns the bit position for the given input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R392" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">393</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitmap_bucket_number.html#pyspark.sql.functions.bitmap_bucket_number">bitmap_bucket_number</a></span>(col)</td><td class="s5" dir="ltr">Returns the bucket number for the given input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R393" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">394</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitmap_construct_agg.html#pyspark.sql.functions.bitmap_construct_agg">bitmap_construct_agg</a></span>(col)</td><td class="s5" dir="ltr">Returns a bitmap with the positions of the bits set from all the values from the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R394" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">395</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitmap_count.html#pyspark.sql.functions.bitmap_count">bitmap_count</a></span>(col)</td><td class="s5" dir="ltr">Returns the number of set bits in the input bitmap.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R395" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">396</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bitmap_or_agg.html#pyspark.sql.functions.bitmap_or_agg">bitmap_or_agg</a></span>(col)</td><td class="s5" dir="ltr">Returns a bitmap that is the bitwise OR of all of the bitmaps from the input column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R396" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">397</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_catalog.html#pyspark.sql.functions.current_catalog">current_catalog</a></span>()</td><td class="s5" dir="ltr">Returns the current catalog.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R397" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">398</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_database.html#pyspark.sql.functions.current_database">current_database</a></span>()</td><td class="s5" dir="ltr">Returns the current database.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R398" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">399</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_schema.html#pyspark.sql.functions.current_schema">current_schema</a></span>()</td><td class="s5" dir="ltr">Returns the current database.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R399" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">400</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.current_user.html#pyspark.sql.functions.current_user">current_user</a></span>()</td><td class="s5" dir="ltr">Returns the current database.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R400" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">401</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.input_file_block_length.html#pyspark.sql.functions.input_file_block_length">input_file_block_length</a></span>()</td><td class="s5" dir="ltr">Returns the length of the block being read, or -1 if not available.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R401" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">402</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.input_file_block_start.html#pyspark.sql.functions.input_file_block_start">input_file_block_start</a></span>()</td><td class="s5" dir="ltr">Returns the start offset of the block being read, or -1 if not available.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R402" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">403</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.md5.html#pyspark.sql.functions.md5">md5</a></span>(col)</td><td class="s5" dir="ltr">Calculates the MD5 digest and returns the value as a 32 character hex string.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R403" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">404</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sha.html#pyspark.sql.functions.sha">sha</a></span>(col)</td><td class="s5" dir="ltr">Returns a sha1 hash value as a hex string of the col.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R404" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">405</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sha1.html#pyspark.sql.functions.sha1">sha1</a></span>(col)</td><td class="s5" dir="ltr">Returns the hex string result of SHA-1.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R405" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">406</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sha2.html#pyspark.sql.functions.sha2">sha2</a></span>(col, numBits)</td><td class="s5" dir="ltr">Returns the hex string result of SHA-2 family of hash functions (SHA-224, SHA-256, SHA-384, and SHA-512).</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R406" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">407</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.crc32.html#pyspark.sql.functions.crc32">crc32</a></span>(col)</td><td class="s5" dir="ltr">Calculates the cyclic redundancy check value (CRC32) of a binary column and returns the value as a bigint.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R407" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">408</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hash.html#pyspark.sql.functions.hash">hash</a></span>(*cols)</td><td class="s5" dir="ltr">Calculates the hash code of given columns, and returns the result as an int column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R408" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">409</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xxhash64.html#pyspark.sql.functions.xxhash64">xxhash64</a></span>(*cols)</td><td class="s5" dir="ltr">Calculates the hash code of given columns using the 64-bit variant of the xxHash algorithm, and returns the result as a long column.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R409" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">410</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.assert_true.html#pyspark.sql.functions.assert_true">assert_true</a></span>(col[, errMsg])</td><td class="s5" dir="ltr">Returns null if the input column is true; throws an exception with the provided error message otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R410" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">411</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.raise_error.html#pyspark.sql.functions.raise_error">raise_error</a></span>(errMsg)</td><td class="s5" dir="ltr">Throws an exception with the provided error message.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R411" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">412</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.reflect.html#pyspark.sql.functions.reflect">reflect</a></span>(*cols)</td><td class="s5" dir="ltr">Calls a method with reflection.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R412" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">413</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hll_sketch_estimate.html#pyspark.sql.functions.hll_sketch_estimate">hll_sketch_estimate</a></span>(col)</td><td class="s5" dir="ltr">Returns the estimated number of unique values given the binary representation of a Datasketches HllSketch.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R413" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">414</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hll_union.html#pyspark.sql.functions.hll_union">hll_union</a></span>(col1, col2[, allowDifferentLgConfigK])</td><td class="s5" dir="ltr">Merges two binary representations of Datasketches HllSketch objects, using a Datasketches Union object.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R414" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">415</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.java_method.html#pyspark.sql.functions.java_method">java_method</a></span>(*cols)</td><td class="s5" dir="ltr">Calls a method with reflection.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R415" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">416</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.stack.html#pyspark.sql.functions.stack">stack</a></span>(*cols)</td><td class="s5" dir="ltr">Separates col1, …, colk into n rows.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R416" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">417</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.try_aes_decrypt.html#pyspark.sql.functions.try_aes_decrypt">try_aes_decrypt</a></span>(input, key[, mode, padding, aad])</td><td class="s5" dir="ltr">This is a special version of aes_decrypt that performs the same operation, but returns a NULL value instead of raising an error if the decryption cannot be performed.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R417" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">418</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.typeof.html#pyspark.sql.functions.typeof">typeof</a></span>(col)</td><td class="s5" dir="ltr">Return DDL-formatted type string for the data type of the input.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R418" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">419</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.user.html#pyspark.sql.functions.user">user</a></span>()</td><td class="s5" dir="ltr">Returns the current database.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R419" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">420</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.version.html#pyspark.sql.functions.version">version</a></span>()</td><td class="s5" dir="ltr">Returns the Spark version.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R420" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">421</div></th><td class="s4" dir="ltr" colspan="3">Predicate Functions</td></tr><tr style="height: 20px"><th id="1474227261R421" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">422</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.equal_null.html#pyspark.sql.functions.equal_null">equal_null</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns same result as the EQUAL(=) operator for non-null operands, but returns true if both are null, false if one of the them is null.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R422" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">423</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ifnull.html#pyspark.sql.functions.ifnull">ifnull</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns col2 if col1 is null, or col1 otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R423" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">424</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.isnotnull.html#pyspark.sql.functions.isnotnull">isnotnull</a></span>(col)</td><td class="s5" dir="ltr">Returns true if col is not null, or false otherwise.</td><td class="s6" dir="ltr">Si</td></tr><tr style="height: 20px"><th id="1474227261R424" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">425</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.nullif.html#pyspark.sql.functions.nullif">nullif</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns null if col1 equals to col2, or col1 otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R425" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">426</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.nvl.html#pyspark.sql.functions.nvl">nvl</a></span>(col1, col2)</td><td class="s5" dir="ltr">Returns col2 if col1 is null, or col1 otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R426" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">427</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.nvl2.html#pyspark.sql.functions.nvl2">nvl2</a></span>(col1, col2, col3)</td><td class="s5" dir="ltr">Returns col2 if col1 is not null, or col3 otherwise.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R427" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">428</div></th><td class="s4" dir="ltr" colspan="3">Xml Functions</td></tr><tr style="height: 20px"><th id="1474227261R428" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">429</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath.html#pyspark.sql.functions.xpath">xpath</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a string array of values within the nodes of xml that match the XPath expression.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R429" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">430</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_boolean.html#pyspark.sql.functions.xpath_boolean">xpath_boolean</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns true if the XPath expression evaluates to true, or if a matching node is found.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R430" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">431</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_double.html#pyspark.sql.functions.xpath_double">xpath_double</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a double value, the value zero if no match is found, or NaN if a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R431" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">432</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_float.html#pyspark.sql.functions.xpath_float">xpath_float</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a float value, the value zero if no match is found, or NaN if a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R432" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">433</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_int.html#pyspark.sql.functions.xpath_int">xpath_int</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns an integer value, or the value zero if no match is found, or a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R433" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">434</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_long.html#pyspark.sql.functions.xpath_long">xpath_long</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a long integer value, or the value zero if no match is found, or a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R434" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">435</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_number.html#pyspark.sql.functions.xpath_number">xpath_number</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a double value, the value zero if no match is found, or NaN if a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R435" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">436</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_short.html#pyspark.sql.functions.xpath_short">xpath_short</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns a short integer value, or the value zero if no match is found, or a match is found but the value is non-numeric.</td><td class="s6"></td></tr><tr style="height: 20px"><th id="1474227261R436" style="height: 20px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 20px">437</div></th><td class="s5" dir="ltr"><span style="font-size:8pt;text-decoration:underline;text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;"><a target="_blank" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.xpath_string.html#pyspark.sql.functions.xpath_string">xpath_string</a></span>(xml, path)</td><td class="s5" dir="ltr">Returns the text contents of the first xml node that matches the XPath expression.</td><td class="s6"></td></tr></tbody></table></div>